{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NWa7Xo6PkIl3",
    "outputId": "b186c3b3-e0cf-423c-922c-94e64702f818"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0 0.5.0\n",
      "GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import grad\n",
    "import torchvision\n",
    "from torchvision import models, datasets, transforms\n",
    "import torch.nn.functional as func\n",
    "#torch.manual_seed(50)\n",
    "\n",
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "print(torch.__version__, torchvision.__version__)\n",
    "print (torch.cuda.get_device_name(device='cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda:0\n"
     ]
    }
   ],
   "source": [
    "# dst = datasets.CIFAR100(\"~/.torch\", download=True)\n",
    "# dst = datasets.MNIST(\"~/.torch\", download=True)\n",
    "\n",
    "tp = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.CenterCrop(32),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "tt = transforms.ToPILImage()\n",
    "\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "print(\"Running on %s\" % device)\n",
    "\n",
    "def label_to_onehot(target, num_classes=106):\n",
    "    target = torch.unsqueeze(target, 1)\n",
    "    onehot_target = torch.zeros(target.size(0), num_classes, device=target.device)\n",
    "    onehot_target.scatter_(1, target, 1)\n",
    "    return onehot_target\n",
    "\n",
    "def cross_entropy_for_onehot(pred, target):\n",
    "    return torch.mean(torch.sum(- target * F.log_softmax(pred, dim=-1), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AorI020iVjjS"
   },
   "outputs": [],
   "source": [
    "# def weights_init(m):\n",
    "#     if hasattr(m, \"weight\"):\n",
    "#         m.weight.data.uniform_(-0.5, 0.5)\n",
    "#         nn.init.xavier_uniform_(m.weight.data)\n",
    "#     if hasattr(m, \"bias\"):\n",
    "#         #m.bias.data.uniform_(-0.5, 0.5)\n",
    "#         #nn.init.xavier_uniform(m.bias.data)\n",
    "#         m.bias.data.fill_(0)\n",
    "\n",
    "\n",
    "\n",
    "# class LeNet(nn.Module):\n",
    "\n",
    "#     def __init__(self):\n",
    "\n",
    "#         super(LeNet, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 6, kernel_size=5,stride=2)\n",
    "#         self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=2)\n",
    "#         self.fc1 = nn.Linear(16*5*5, 256)\n",
    "#         self.fc2 = nn.Linear(256, 120)\n",
    "#         self.fc3 = nn.Linear(120, 106)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         #x = func.relu(self.conv1(x))\n",
    "#         x = func.sigmoid(self.conv1(x))\n",
    "#         #x = func.max_pool2d(x, 2)\n",
    "#         #x = func.relu(self.conv2(x))\n",
    "#         x = func.sigmoid(self.conv2(x))\n",
    "#         #x = func.max_pool2d(x, 2)\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         #x = func.relu(self.fc1(x))\n",
    "#         x = func.sigmoid(self.fc1(x))\n",
    "#         #x = func.relu(self.fc2(x))\n",
    "#         x = func.sigmoid(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "#         return x\n",
    "\n",
    "    \n",
    "    \n",
    "# def weights_init(m):\n",
    "#     if hasattr(m, \"weight\"):\n",
    "#         m.weight.data.uniform_(-0.3, 0.3)\n",
    "#     if hasattr(m, \"bias\"):\n",
    "#         m.bias.data.uniform_(-0.3, 0.3)\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    if hasattr(m, \"weight\"):\n",
    "        m.weight.data.uniform_(-0.5, 0.5)\n",
    "    if hasattr(m, \"bias\"):\n",
    "        m.bias.data.uniform_(-0.5, 0.5)\n",
    "\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        act = nn.Sigmoid\n",
    "        #act = nn.ReLU\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(3, 12, kernel_size=5, padding=5//2, stride=2),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5//2, stride=2),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5//2, stride=1),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5//2, stride=1),\n",
    "            act(),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(768, 106)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.body(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        # print(out.size())\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "net = LeNet().to(device)\n",
    "net.apply(weights_init)\n",
    "\n",
    "\n",
    "\n",
    "#criterion = cross_entropy_for_onehot\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AorI020iVjjS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2801, 32, 32, 3)\n",
      "(934, 32, 32, 3)\n",
      "106\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data\n",
    "\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.model_selection import train_test_split\n",
    "lfw_people=fetch_lfw_people(min_faces_per_person=14,color=True,slice_=(slice(61,189),slice(61,189)),resize=0.25) #14\n",
    "x=lfw_people.images\n",
    "y=lfw_people.target\n",
    "\n",
    "target_names=lfw_people.target_names\n",
    "n_classes=target_names.shape[0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25,shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "print (X_train.shape)\n",
    "print (X_test.shape)\n",
    "print (n_classes)\n",
    "\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AorI020iVjjS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fininshed training\n",
      "0.007494646680942184\n",
      "fininshed testing\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 32, 32, 3)\n",
    "X_test = X_test.reshape(X_test.shape[0], 32, 32, 3)\n",
    "#X_train = torch.transpose\n",
    "#X_train = X_train.astype('float32')\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "x_train = torch.FloatTensor(X_train).to(device)\n",
    "x_train = x_train.transpose(2,3).transpose(1,2)\n",
    "y_train = torch.LongTensor(y_train).to(device)\n",
    "\n",
    "x_test = torch.FloatTensor(X_test).to(device)\n",
    "x_test = x_test.transpose(2,3).transpose(1,2)\n",
    "y_test = torch.LongTensor(y_test).to(device)\n",
    "\n",
    "\n",
    "training = data.TensorDataset(x_train,y_train)\n",
    "\n",
    "testing = data.TensorDataset(x_test,y_test)\n",
    "\n",
    "dst_tensor=training\n",
    "\n",
    "criterion_train = nn.CrossEntropyLoss()\n",
    "optimizer_train = optim.Adam(net.parameters(),lr=0.01)#,momentum=0.9)\n",
    "trainloader = torch.utils.data.DataLoader(training,batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(0):\n",
    "\n",
    "    for i,data in enumerate(trainloader,0):\n",
    "    #for data in trainloader:\n",
    "        #if i<=10: \n",
    "\n",
    "            inputs,label = data\n",
    "\n",
    "            inputs,label =  Variable(inputs).to(device),Variable(label).to(device)\n",
    "\n",
    "            optimizer_train.zero_grad()\n",
    "            outputs_benign=net(inputs)\n",
    "\n",
    "            loss_benign =  criterion_train(outputs_benign,label)\n",
    "\n",
    "            loss_benign.backward()\n",
    "            #sgd_update(net.parameters())\n",
    "\n",
    "            optimizer_train.step()\n",
    "            \n",
    "            testloader = torch.utils.data.DataLoader(testing,batch_size=934, shuffle=False)\n",
    "\n",
    "            acc =0.0\n",
    "            for ji,tdata in enumerate(testloader,0):\n",
    "\n",
    "                tinputs,tlabel = tdata\n",
    "\n",
    "                tinputs,tlabel =  Variable(tinputs).to(device),Variable(tlabel).to(device)\n",
    "\n",
    "                toutputs=net(tinputs)\n",
    "\n",
    "                tpredict = torch.argmax(toutputs, dim=1)\n",
    "\n",
    "\n",
    "                for mi in range(934):\n",
    "\n",
    "\n",
    "\n",
    "                    if tpredict[mi] == tlabel[mi]:\n",
    "                        acc=acc+1\n",
    "\n",
    "            accuracy = acc / 934\n",
    "            print (accuracy)\n",
    "            print ('fininshed testing')\n",
    "            if accuracy>0.18:\n",
    "                break\n",
    "\n",
    "\n",
    "print ('fininshed training')\n",
    "#torch.save(net.state_dict()\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testing,batch_size=934, shuffle=False)\n",
    "\n",
    "acc =0.0\n",
    "for ji,tdata in enumerate(testloader,0):\n",
    "\n",
    "    tinputs,tlabel = tdata\n",
    "\n",
    "    tinputs,tlabel =  Variable(tinputs).to(device),Variable(tlabel).to(device)\n",
    "\n",
    "    toutputs=net(tinputs)\n",
    "    \n",
    "    tpredict = torch.argmax(toutputs, dim=1)\n",
    "    \n",
    "   \n",
    "    for mi in range(934):\n",
    "        \n",
    "        \n",
    "\n",
    "        if tpredict[mi] == tlabel[mi]:\n",
    "            acc=acc+1\n",
    "\n",
    "accuracy = acc / 934\n",
    "print (accuracy)\n",
    "print ('fininshed testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now starting 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wenqi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:118: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-804f6154555b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0miters\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                             \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/lbfgs.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    430\u001b[0m                     \u001b[0;31m# the reason we do this: in a stochastic setting,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m                     \u001b[0;31m# no use to re-evaluate that function here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m                     \u001b[0mflat_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gather_flat_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                     \u001b[0mopt_cond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflat_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mtolerance_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-804f6154555b>\u001b[0m in \u001b[0;36mclosure\u001b[0;34m()\u001b[0m\n\u001b[1;32m    183\u001b[0m                                 \u001b[0mlasso\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                                 \u001b[0mridge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                                 \u001b[0mgrad_diff\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#+ 0.0*lasso +0.01*ridge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pytorch_msssim import ssim\n",
    "\n",
    "#dgc_rate_list = [20,30,40,50,70, 80,90]\n",
    "\n",
    "#for epoch in range(1):\n",
    "#for dgc_rate in dgc_rate_list:\n",
    "gau_rate_list = [100]\n",
    "for gau_rate in gau_rate_list:\n",
    "\n",
    "    \n",
    "    print('now starting',gau_rate)\n",
    "\n",
    "    for iter_,data in enumerate(trainloader,1):\n",
    "        \n",
    "        if iter_ != 1:\n",
    "            break\n",
    "   \n",
    "        ######### honest partipant #########\n",
    "        img_index = 12   #use img_index\n",
    "        dst_pil = tt(dst_tensor[img_index][0].cpu())   #use img_index\n",
    "\n",
    "        gt_data = tp(dst_pil).to(device)\n",
    "        gt_data = torch.unsqueeze(gt_data,0)\n",
    "\n",
    "        gt_label = dst_tensor[img_index][1].long().to(device) #use img_index\n",
    "        gt_label = gt_label.view(1, )\n",
    "        gt_onehot_label = label_to_onehot(gt_label, num_classes=106)\n",
    "\n",
    "        plt.imshow(dst_pil)\n",
    "        plt.axis('off')\n",
    "        plt.savefig(\"./attack_image/lfw_gt_nips_appendix\")\n",
    "\n",
    "\n",
    "\n",
    "        batch =2  #\n",
    "        for bat in range(batch-1):\n",
    "            dst_pil = tt(dst_tensor[img_index+1+bat][0].cpu())   #use img_index\n",
    "            tmp = torch.unsqueeze(tp(dst_pil).to(device),0)\n",
    "            #print(tmp.shape)\n",
    "            gt_data = torch.cat((gt_data,tmp),0)\n",
    "\n",
    "            gt_label_tmp = dst_tensor[img_index+1+bat][1].long().to(device) #use img_index\n",
    "            gt_label_tmp = gt_label_tmp.view(1, )\n",
    "            gt_label = torch.cat((gt_label,gt_label_tmp),0)\n",
    "            gt_onehot_label = torch.cat((gt_onehot_label,label_to_onehot(gt_label_tmp, num_classes=106)),0)\n",
    "\n",
    "            plt.imshow(dst_pil)\n",
    "            #plt.savefig(\"./original/index_%s_label_%s\"%(bat+1,gt_label_tmp.item()))\n",
    "\n",
    "            #plt.title(\"Ground truth image\")\n",
    "            #print(\"GT label is %d.\" % gt_label.item(), \"\\nOnehot label is %d.\" % torch.argmax(gt_onehot_label, dim=-1).item())\n",
    "\n",
    "\n",
    "        gt_label = torch.reshape(gt_label,(-1,1))    \n",
    "        #print (gt_data.shape)\n",
    "        #print (gt_label.shape)\n",
    "        #print (gt_onehot_label.shape)\n",
    "\n",
    "\n",
    "        # compute original gradient \n",
    "        dy_dx = []\n",
    "        original_dy_dx=[]\n",
    "        original_pred = []\n",
    "        for item in range(batch):\n",
    "            gt_data_single = torch.unsqueeze(gt_data[item],0)\n",
    "            out = net(gt_data_single)\n",
    "            #y = criterion(out, gt_onehot_label[item])\n",
    "            y = criterion(out, gt_label[item])\n",
    "            dy_dx = torch.autograd.grad(y, net.parameters(),retain_graph=True)\n",
    "            original_dy_dx_tmp = list((_.detach().clone() for _ in dy_dx))\n",
    "            original_dy_dx.append(original_dy_dx_tmp)\n",
    "            out_tmp = out.detach().clone()\n",
    "            original_pred.append(out_tmp)\n",
    "            \n",
    "            \n",
    "        #if gaussian noise or laplace\n",
    "        m = torch.distributions.laplace.Laplace(torch.tensor([0.0]), torch.tensor([1/gau_rate]))\n",
    "        for item in range(batch):\n",
    "            for layer_idx in range(10):\n",
    "                #original_dy_dx[item][layer_idx] =  original_dy_dx[item][layer_idx] + torch.empty(original_dy_dx[item][layer_idx].size()).normal_(mean=0,std=1/gau_rate).to(device)\n",
    "                original_dy_dx[item][layer_idx] =  original_dy_dx[item][layer_idx] + torch.squeeze(m.sample(sample_shape=original_dy_dx[item][layer_idx].size()),dim=-1).to(device)\n",
    "                #break\n",
    "        ##if deep gradient compression\n",
    "        #print (original_dy_dx[0][0][0])\n",
    "        #for item in range(batch):\n",
    "        #    for layer_idx in range(10):\n",
    "        #        if layer_idx == 0:    \n",
    "        #            flat_dy_dx = torch.flatten(original_dy_dx[item][layer_idx])\n",
    "        #        else:\n",
    "        #            flat_dy_dx = torch.cat((flat_dy_dx,torch.flatten(original_dy_dx[item][layer_idx])),0)\n",
    "        #sorted_dy_dx = flat_dy_dx.abs().sort()\n",
    "        #size = np.asarray(list(flat_dy_dx.shape))\n",
    "        #thresh = sorted_dy_dx[0][int(size * dgc_rate/100.0)]\n",
    "        #print (size)\n",
    "        #print (int(size * dgc_rate/100.0))\n",
    "        #print (thresh)\n",
    "        #print (sorted_dy_dx[0][-1])\n",
    "        #for item in range(batch):\n",
    "        #    for layer_idx in range(10):\n",
    "        #        shape_tmp = original_dy_dx[item][layer_idx].size()\n",
    "        #        flat_dy_dx_prune = torch.flatten(original_dy_dx[item][layer_idx])\n",
    "        #        size_tmp = np.asarray(list(flat_dy_dx_prune.shape))\n",
    "        #        for m in range(int(size_tmp)):\n",
    "        #            if flat_dy_dx_prune[m].abs()<=thresh:\n",
    "        #                flat_dy_dx_prune[m] = 0\n",
    "        #        original_dy_dx[item][layer_idx] = flat_dy_dx_prune.view(shape_tmp)\n",
    "        #print (original_dy_dx[0][0][0])\n",
    "              \n",
    "\n",
    "        # generate dummy data and label\n",
    "        import time\n",
    "\n",
    "        #if iter_ % 10 ==0: \n",
    "        if iter_ == 1:\n",
    "            \n",
    "            #print ('epoch',epoch,'iter',iter_)\n",
    "            for item in range(1):\n",
    "                start = time.clock()\n",
    "                for rd in range(1):\n",
    "\n",
    "                    torch.manual_seed(100*rd)\n",
    "\n",
    "                    pat_1 = torch.rand([3,16,16])\n",
    "                    pat_2 = torch.cat((pat_1,pat_1),dim=1)\n",
    "                    pat_4 = torch.cat((pat_2,pat_2),dim=2)\n",
    "                    dummy_data = torch.unsqueeze(pat_4,dim=0).to(device).requires_grad_(True)     \n",
    "\n",
    "                    dummy_unsqueeze=torch.unsqueeze(gt_onehot_label[item],dim=0)\n",
    "\n",
    "                    dummy_label = torch.randn(gt_onehot_label[item].size()).to(device).requires_grad_(True)\n",
    "                    label_pred = torch.argmin(torch.sum(original_dy_dx[item][-2], dim=-1), dim=-1).detach().reshape((1,)).requires_grad_(False)\n",
    "                    label_pred_onehot = label_to_onehot(label_pred, num_classes=106)\n",
    "\n",
    "                    plt.imshow(tt(dummy_data[0].cpu()))\n",
    "                    plt.title(\"Dummy data\")\n",
    "                    #plt.savefig(\"./random_seed/index_%s_rand_seed_%s_label_%s\"%(item,rd,torch.argmax(dummy_label, dim=-1).item()))\n",
    "\n",
    "                    plt.clf()\n",
    "                    #print(\"Dummy label is %d.\" % torch.argmax(dummy_label, dim=-1).item())\n",
    "                    #print(\"stolen label is %d.\" % label_pred.item())\n",
    "\n",
    "                    #optimizer = torch.optim.LBFGS([dummy_data,dummy_label])\n",
    "                    optimizer = torch.optim.LBFGS([dummy_data,])\n",
    "\n",
    "\n",
    "                    history = []\n",
    "                    history_batch = []\n",
    "                    history_grad = []\n",
    "\n",
    "                    percept_dis = np.zeros(100)\n",
    "                    recover_dis = np.zeros(100)\n",
    "                    for iters in range(100):\n",
    "\n",
    "                        percept_dis[iters]=ssim(dummy_data,torch.unsqueeze(gt_data[item],dim=0),data_range=0).item()\n",
    "                        recover_dis[iters]=torch.dist(dummy_data,torch.unsqueeze(gt_data[item],dim=0),2).item()\n",
    "\n",
    "                        history.append(tt(dummy_data[0].cpu()))\n",
    "\n",
    "                        def closure():\n",
    "                            optimizer.zero_grad()\n",
    "\n",
    "                            pred = net(dummy_data) \n",
    "                            dummy_onehot_label = F.softmax(dummy_label, dim=-1)\n",
    "                            #dummy_loss = criterion(pred, dummy_onehot_label) # TODO: fix the gt_label to dummy_label in both code and slides.\n",
    "\n",
    "                            #dummy_loss = criterion(pred, label_pred_onehot)\n",
    "                            dummy_loss = criterion(pred, label_pred)\n",
    "\n",
    "\n",
    "                            dummy_dy_dx = torch.autograd.grad(dummy_loss, net.parameters(), create_graph=True)\n",
    "                            #dummy_dy_dp = torch.autograd.grad(dummy_loss, dummy_data, create_graph=True)\n",
    "                            #print (dummy_dy_dp[0].shape)\n",
    "\n",
    "                            grad_diff = 0\n",
    "                            grad_count = 0\n",
    "                            #count =0\n",
    "                            for gx, gy in zip(dummy_dy_dx, original_dy_dx[item]): # TODO: fix the variablas here\n",
    "\n",
    "                                #if iters==500 or iters== 1200:\n",
    "                                #    print (gx[0])\n",
    "                                #    print ('hahaha')\n",
    "                                #    print (gy[0])\n",
    "                                lasso = torch.norm(dummy_data,p=1)\n",
    "                                ridge = torch.norm(dummy_data,p=2)\n",
    "                                grad_diff += ((gx - gy) ** 2).sum() #+ 0.0*lasso +0.01*ridge\n",
    "\n",
    "\n",
    "                                grad_count += gx.nelement()\n",
    "\n",
    "                                #if count == 9:\n",
    "                                #    break\n",
    "                                #count=count+1\n",
    "                            # grad_diff = grad_diff / grad_count * 1000\n",
    "                            grad_diff.backward()\n",
    "                            #print (count)\n",
    "\n",
    "                            #print (dummy_dy_dx)\n",
    "                            #print (original_dy_dx)\n",
    "\n",
    "\n",
    "                            return grad_diff\n",
    "\n",
    "\n",
    "\n",
    "                        optimizer.step(closure)\n",
    "                        if iters % 5 == 0: \n",
    "                            current_loss = closure()\n",
    "                            #if iters == 0: \n",
    "                            #print (\"%.8f\" % current_loss.item())\n",
    "                            #print(iters, \"%.8f\" % current_loss.item())\n",
    "\n",
    "                    #     for bat in range(batch-1):\n",
    "                    #         history_batch.append(tt(dummy_data[bat].cpu()))\n",
    "\n",
    "                    #plt.figure(figsize=(30, 20))\n",
    "                    #for i in range(100):\n",
    "                    #    plt.subplot(10, 10, i + 1)\n",
    "                    #    plt.imshow(history[i * 5])\n",
    "                    #    plt.title(\"iter=%d\" % (i * 5))\n",
    "                    #    plt.axis('off')\n",
    "                    #print(\"Dummy label is %d.\" % torch.argmax(dummy_label, dim=-1).item())\n",
    "\n",
    "                    #np.savetxt('./attack_image/lfw_ssim_idx_%s_laplace_%s'%(item,gau_rate),percept_dis,fmt=\"%4f\")\n",
    "                    #np.savetxt('./attack_image/lfw_mse_idx_%s_laplace_%s'%(item,gau_rate),recover_dis,fmt=\"%4f\")\n",
    "                    #plt.savefig(\"./attack_image/lfw_index_%s_laplace_%s\"%(item,gau_rate))\n",
    "\n",
    "                    #plt.clf()\n",
    "                    \n",
    "                    pinp = np.argmin(recover_dis)\n",
    "                    plt.imshow(history[pinp])\n",
    "                    plt.axis('off')\n",
    "                    \n",
    "                    #plt.figure(figsize=(15, 10))\n",
    "                    #for i in range(60):\n",
    "                    #    plt.subplot(6, 10, i + 1)\n",
    "                    #    plt.imshow(history[i * 14 ], cmap='gray')\n",
    "                    #    plt.title(\"iter=%d\" % (i*14))\n",
    "                    #    plt.axis('off')\n",
    "                    plt.savefig(\"./attack_image/lfw_idx_%s_laplace_%s_nips\"%(item,gau_rate))\n",
    "                    \n",
    "                #duration = time.clock()-start\n",
    "                #print (\"Running time is %.4f.\" %(duration/10.0) )\n",
    "                #print (duration)\n",
    "                \n",
    "        \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "################################################### training when set to epoch\n",
    "\n",
    "#         #if epoch>=1:\n",
    "#         #if i==1:\n",
    "#             #break\n",
    "#         #print (iter_)\n",
    "#         inputs,label = data\n",
    "\n",
    "#         inputs,label =  Variable(inputs).to(device),Variable(label).to(device)\n",
    "\n",
    "#         optimizer_train.zero_grad()\n",
    "\n",
    "\n",
    "#         outputs_benign=net(inputs)\n",
    "#         #outputs_benign = F.softmax(outputs_benign, dim=-1)\n",
    "#         #print (outputs_benign[0])\n",
    "\n",
    "\n",
    "#         loss_benign =  criterion_train(outputs_benign,label)\n",
    "\n",
    "#         #print(\"loss computed\")\n",
    "#         loss_benign.backward()\n",
    "#         #print(\"loss BP\")\n",
    "#         optimizer_train.step()\n",
    "#         #sgd_update(net.parameters())\n",
    "\n",
    "#         #if i%2000==0:\n",
    "#         #print (loss_benign.item())\n",
    "#         #torch.save(net.state_dict(),'./LFW_net.pth')  \n",
    "\n",
    "#         #if  iter_%50==0:\n",
    "#         #    print ('attack',iter_)\n",
    "       \n",
    "        \n",
    "#         print ('fininshed training')\n",
    "#         break\n",
    "###############################   testing\n",
    "    \n",
    "#         total = len(y_test)\n",
    "#         acc =0.0\n",
    "#         for ct in range(total):\n",
    "#             testing_data = tt(testing[ct][0].cpu())\n",
    "#             testing_data1 = tp(testing_data).to(device)\n",
    "#             testing_data2 = testing_data1.view(1, *testing_data1.size())\n",
    "#             y_pred = net(testing_data2)\n",
    "#             predicted = torch.argmax(y_pred)\n",
    "\n",
    "#             if predicted == y_test[ct]:\n",
    "#                 acc=acc+1\n",
    "#         accuracy = acc / total\n",
    "#         print (accuracy)\n",
    "#         print ('fininshed testing')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AorI020iVjjS",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 3, 32, 32])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 106])\n",
      "Dummy label is 42.\n",
      "stolen label is 6.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wenqi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:79: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "/home/wenqi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:203: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.941089\n",
      "12.076419830322266\n",
      "fininshed training\n",
      "0.0032119914346895075\n",
      "fininshed testing\n",
      "torch.Size([100, 3, 32, 32])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 106])\n",
      "Dummy label is 42.\n",
      "stolen label is 6.\n",
      "98.18773599999999\n",
      "11.408146858215332\n",
      "fininshed training\n",
      "0.03747323340471092\n",
      "fininshed testing\n",
      "torch.Size([100, 3, 32, 32])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 106])\n",
      "Dummy label is 42.\n",
      "stolen label is 6.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-eba14212c9a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0miters\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                         \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/lbfgs.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_old\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                     \u001b[0mbe_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_dirs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mro\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                     \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbe_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_stps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprev_flat_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pytorch_msssim import ssim\n",
    "\n",
    "\n",
    "for epoch in range(1):\n",
    "\n",
    "    for iter_,data in enumerate(trainloader,1):\n",
    "   \n",
    "        ######### honest partipant #########\n",
    "        img_index = 6   #use img_index\n",
    "        dst_pil = tt(dst_tensor[img_index][0].cpu())   #use img_index\n",
    "\n",
    "        gt_data = tp(dst_pil).to(device)\n",
    "        gt_data = torch.unsqueeze(gt_data,0)\n",
    "\n",
    "        gt_label = dst_tensor[img_index][1].long().to(device) #use img_index\n",
    "        gt_label = gt_label.view(1, )\n",
    "        gt_onehot_label = label_to_onehot(gt_label, num_classes=106)\n",
    "\n",
    "        plt.imshow(dst_pil)\n",
    "        #plt.savefig(\"./original/index_%s_label_%s\"%(img_index,gt_label.item()))\n",
    "\n",
    "\n",
    "\n",
    "        batch =100  #\n",
    "        for bat in range(batch-1):\n",
    "            dst_pil = tt(dst_tensor[img_index+1+bat][0].cpu())   #use img_index\n",
    "            tmp = torch.unsqueeze(tp(dst_pil).to(device),0)\n",
    "            #print(tmp.shape)\n",
    "            gt_data = torch.cat((gt_data,tmp),0)\n",
    "\n",
    "            gt_label_tmp = dst_tensor[img_index+1+bat][1].long().to(device) #use img_index\n",
    "            gt_label_tmp = gt_label_tmp.view(1, )\n",
    "            gt_label = torch.cat((gt_label,gt_label_tmp),0)\n",
    "            gt_onehot_label = torch.cat((gt_onehot_label,label_to_onehot(gt_label_tmp, num_classes=106)),0)\n",
    "\n",
    "            plt.imshow(dst_pil)\n",
    "            #plt.savefig(\"./original/index_%s_label_%s\"%(bat+1,gt_label_tmp.item()))\n",
    "\n",
    "            #plt.title(\"Ground truth image\")\n",
    "            #print(\"GT label is %d.\" % gt_label.item(), \"\\nOnehot label is %d.\" % torch.argmax(gt_onehot_label, dim=-1).item())\n",
    "\n",
    "\n",
    "        gt_label = torch.reshape(gt_label,(-1,1))    \n",
    "        print (gt_data.shape)\n",
    "        print (gt_label.shape)\n",
    "        print (gt_onehot_label.shape)\n",
    "\n",
    "\n",
    "        # compute original gradient \n",
    "        dy_dx = []\n",
    "        original_dy_dx=[]\n",
    "        original_pred = []\n",
    "        for item in range(batch):\n",
    "            gt_data_single = torch.unsqueeze(gt_data[item],0)\n",
    "            out = net(gt_data_single)\n",
    "            #y = criterion(out, gt_onehot_label[item])\n",
    "            y = criterion(out, gt_label[item])\n",
    "            dy_dx = torch.autograd.grad(y, net.parameters(),retain_graph=True)\n",
    "            original_dy_dx_tmp = list((_.detach().clone() for _ in dy_dx))\n",
    "            original_dy_dx.append(original_dy_dx_tmp)\n",
    "            out_tmp = out.detach().clone()\n",
    "            original_pred.append(out_tmp)\n",
    "\n",
    "            #dy_dx.append(torch.autograd.grad(y, net.parameters()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # share the gradients with other clients\n",
    "        #original_dy_dx = list((_.detach().clone() for _ in dy_dx))\n",
    "\n",
    "\n",
    "        # generate dummy data and label\n",
    "        import time\n",
    "\n",
    "\n",
    "        for item in range(1):\n",
    "            start = time.clock()\n",
    "            for rd in range(1):\n",
    "\n",
    "                torch.manual_seed(100*rd)\n",
    "        \n",
    "                pat_1 = torch.rand([3,16,16])\n",
    "                pat_2 = torch.cat((pat_1,pat_1),dim=1)\n",
    "                pat_4 = torch.cat((pat_2,pat_2),dim=2)\n",
    "                dummy_data = torch.unsqueeze(pat_4,dim=0).to(device).requires_grad_(True)     \n",
    "\n",
    "                dummy_unsqueeze=torch.unsqueeze(gt_onehot_label[item],dim=0)\n",
    "\n",
    "                dummy_label = torch.randn(dummy_unsqueeze.size()).to(device).requires_grad_(True)\n",
    "                label_pred=torch.argmin(torch.sum(original_dy_dx[item][-2], dim=-1), \n",
    "                                        dim=-1).detach().reshape((1,)).requires_grad_(False)\n",
    "                #print (original_dy_dx[item][-1].shape)\n",
    "                #print (original_dy_dx[item][-1].argmin())\n",
    "\n",
    "                #print (torch.sum(original_dy_dx[item][-2], dim=-1).argmin())\n",
    "\n",
    "                plt.imshow(tt(dummy_data[0].cpu()))\n",
    "                plt.title(\"Dummy data\")\n",
    "                #plt.savefig(\"./random_seed/index_%s_rand_seed_%s_label_%s\"%(item,rd,torch.argmax(dummy_label, dim=-1).item()))\n",
    "\n",
    "                plt.clf()\n",
    "                print(\"Dummy label is %d.\" % torch.argmax(dummy_label, dim=-1).item())\n",
    "                print(\"stolen label is %d.\" % label_pred.item())\n",
    "\n",
    "\n",
    "                #optimizer = torch.optim.LBFGS([dummy_data,dummy_label])\n",
    "                optimizer = torch.optim.LBFGS([dummy_data,])\n",
    "                #optimizer = torch.optim.AdamW([dummy_data,],lr=0.01)\n",
    "\n",
    "\n",
    "                history = []\n",
    "                history_batch = []\n",
    "                history_grad = []\n",
    "                \n",
    "                percept_dis = np.zeros(500)\n",
    "                recover_dis = np.zeros(500)\n",
    "                for iters in range(500):\n",
    "                    \n",
    "                    percept_dis[iters]=ssim(dummy_data,torch.unsqueeze(gt_data[item],dim=0),data_range=0).item()\n",
    "                    recover_dis[iters]=torch.dist(dummy_data,torch.unsqueeze(gt_data[item],dim=0),2).item()\n",
    "                    \n",
    "                    history.append(tt(dummy_data[0].cpu()))\n",
    "\n",
    "                    def closure():\n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                        pred = net(dummy_data) \n",
    "                        #dummy_onehot_label = F.softmax(dummy_label, dim=-1).long()\n",
    "\n",
    "                        #dummy_loss = criterion(pred, dummy_onehot_label) # TODO: fix the gt_label to dummy_label in both code and slides.\n",
    "                        #print (pred)\n",
    "                        #print (label_pred)\n",
    "\n",
    "                        dummy_loss = criterion(pred, label_pred)\n",
    "                        dummy_dy_dx = torch.autograd.grad(dummy_loss, net.parameters(), create_graph=True)\n",
    "                        #dummy_dy_dp = torch.autograd.grad(dummy_loss, dummy_data, create_graph=True)\n",
    "                        #print (dummy_dy_dp[0].shape)  \n",
    "\n",
    "                        grad_diff = 0\n",
    "                        grad_count = 0\n",
    "                        #count =0\n",
    "                        for gx, gy in zip(dummy_dy_dx, original_dy_dx[item]): # TODO: fix the variablas here\n",
    "\n",
    "                            #if iters==500 or iters== 1200:\n",
    "                            #print (gx[0])\n",
    "                            #    print ('hahaha')\n",
    "                            #print (gy[0])\n",
    "                            lasso = torch.norm(dummy_data,p=1)\n",
    "                            ridge = torch.norm(dummy_data,p=2)\n",
    "                            grad_diff += ((gx - gy) ** 2).sum() #+ 0.0*lasso +0.01*ridge \n",
    "\n",
    "                            #print (gx.shape)\n",
    "\n",
    "                            grad_count += gx.nelement()\n",
    "\n",
    "\n",
    "                            #if count == 9:\n",
    "                            #    break\n",
    "                            #count=count+1\n",
    "                        # grad_diff = grad_diff / grad_count * 1000\n",
    "\n",
    "                        #grad_diff += ((original_pred[item]-pred)**2).sum()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        grad_diff.backward()\n",
    "                        #print (count)\n",
    "\n",
    "                        #print (dummy_dy_dx)\n",
    "                        #print (original_dy_dx)\n",
    "\n",
    "\n",
    "                        return grad_diff\n",
    "\n",
    "\n",
    "\n",
    "                    optimizer.step(closure)\n",
    "                    if iters % 5 == 0: \n",
    "                        current_loss = closure()\n",
    "                        #if iters == 0: \n",
    "                        #print (\"%.8f\" % current_loss.item())\n",
    "                        #print(iters, \"%.8f\" % current_loss.item())\n",
    "\n",
    "                #     for bat in range(batch-1):\n",
    "                #         history_batch.append(tt(dummy_data[bat].cpu()))\n",
    "\n",
    "                plt.figure(figsize=(30, 20))\n",
    "                for i in range(100):\n",
    "                    plt.subplot(10, 10, i + 1)\n",
    "                    plt.imshow(history[i * 5])\n",
    "                    plt.title(\"iter=%d\" % (i * 5))\n",
    "                    plt.axis('off')\n",
    "                #print(\"Dummy label is %d.\" % torch.argmax(dummy_label, dim=-1).item())\n",
    "                \n",
    "                #np.savetxt('lfw_ssim_%s'%iter_,percept_dis,fmt=\"%4f\")\n",
    "                #np.savetxt('lfw_mse_%s'%iter_,recover_dis,fmt=\"%4f\")\n",
    "                #plt.savefig(\"./attack_image/index_%s_iter_%s_label_%s\"%(img_index,iter_,torch.argmax(dummy_label, dim=-1).item()))\n",
    "                \n",
    "                plt.clf()\n",
    "            duration = time.clock()-start\n",
    "            #print (\"Running time is %.4f.\" %(duration/10.0) )\n",
    "            print (duration)\n",
    "            \n",
    "            \n",
    "            #if epoch>=1:\n",
    "        #if i==1:\n",
    "            #break\n",
    "        #print (iter_)\n",
    "        inputs,label = data\n",
    "\n",
    "        inputs,label =  Variable(inputs),Variable(label) \n",
    "\n",
    "        optimizer_train.zero_grad()\n",
    "\n",
    "\n",
    "        outputs_benign=net(inputs)\n",
    "        #outputs_benign = F.softmax(outputs_benign, dim=-1)\n",
    "        #print (outputs_benign[0])\n",
    "\n",
    "\n",
    "        loss_benign =  criterion_train(outputs_benign,label)\n",
    "\n",
    "        #print(\"loss computed\")\n",
    "        loss_benign.backward()\n",
    "        #print(\"loss BP\")\n",
    "        optimizer_train.step()\n",
    "\n",
    "        #if i%2000==0:\n",
    "        print (loss_benign.item())\n",
    "        #torch.save(net.state_dict(),'./LFW_net.pth')  \n",
    "\n",
    "  \n",
    "        print ('fininshed training')\n",
    "        total = len(y_test)\n",
    "        acc =0.0\n",
    "        for ct in range(total):\n",
    "            testing_data = tt(testing[ct][0].cpu())\n",
    "            testing_data1 = tp(testing_data).to(device)\n",
    "            testing_data2 = testing_data1.view(1, *testing_data1.size())\n",
    "            y_pred = net(testing_data2)\n",
    "            predicted = torch.argmax(y_pred)\n",
    "\n",
    "            if predicted == y_test[ct]:\n",
    "                acc=acc+1\n",
    "        accuracy = acc / total\n",
    "        print (accuracy)\n",
    "        print ('fininshed testing')\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "colab_type": "code",
    "id": "aokP-jhal96-",
    "outputId": "595e775a-7f91-49a8-cfaa-384c7a320002"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(60):\n",
    "  plt.subplot(6, 10, i + 1)\n",
    "  plt.imshow(history[i * 5])\n",
    "  plt.title(\"iter=%d\" % (i * 5))\n",
    "  plt.axis('off')\n",
    "print(\"Dummy label is %d.\" % torch.argmax(dummy_label, dim=-1).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "for j in range(batch):\n",
    "    for i in range(60):\n",
    "      plt.subplot(6, 10, i + 1)\n",
    "      plt.imshow(history_batch[i * 5+j])\n",
    "      plt.title(\"iter=%d\" % (i * 5+ j))\n",
    "      plt.axis('off')\n",
    "print(\"Dummy label is %d.\" % torch.argmax(dummy_label, dim=-1).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Deep Leakage from Gradients.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
